---
title: "Assignment #4"
author: "Minghao Du"
output:
  word_document: default
  html_notebook: default
---

# Set-up
Load packages. 
```{r}
rm(list = ls())
library(readxl)
library(tidyverse)
library(ggplot2)
```

For this and the next assignments (Assignment 3 and 4), you will use the dataset from https://www.ibm.com/communities/analytics/watson-analytics-blog/it-help-desk/. (the link is now invalid.) 
This data is from an Information Technology (IT) department interested in improving the satisfaction of customers.  
To start their analysis, they constructed this data set of 100,000 closed tickets that were filed at their help desk. 

Load the dataset and save it as ithelp. 
```{r}
ithelp <- read_excel("WA_Fn-UseC_-IT-Help-Desk.xlsx")
```

```{r}
glimpse(ithelp)
```

A total of 100,000 rows. Each row represent an individual request. The data includes:

* Requestor: employee who submitted the ticket
* RequestorSeniority: employeeâ€™s seniority within the company
* ITOwner: IT employee who serviced the ticket
* FileAgainst: functional area against which the ticket was filed (systems, software, hardware, access)
* TicketType: whether the ticket was a request for new services or an issue with existing services
* Severity: submitter-assigned severity of the ticket
* Priority: IT-assigned priority of the ticket
* daysOpen: number of days the ticket was open
* Satisfaction: satisfaction with the resolution of the ticket (reported by the submitter)

```{r}
summary(ithelp)
```

Some 'character' variables behave unexpectedly. Let's convert all character variables into factors, which indicate categorical variables in R. 

```{r}
ithelp<-ithelp%>%
  mutate(ticket=as.factor(ticket),
         Requestor=as.factor(Requestor),
         RequestorSeniority=as.factor(RequestorSeniority),
         ITOwner=as.factor(ITOwner),
         FiledAgainst=as.factor(FiledAgainst),
         TicketType=as.factor(TicketType),
         Severity=as.factor(Severity),
         Priority=as.factor(Priority),
         Satisfaction=as.factor(Satisfaction))
```

Let's check the summary again. 
```{r}
summary(ithelp)
```

It turns out that there are many cases with "Unknown" Satisfaction. Let's exclude these cases from the analysis (Step 1: filter). Next, we may build a multi-class classification model (Unsatisfied, Satisfied, Highly satisfied), but let's simplify it to a binary classifier and identify "Unsatisfied" cases, which are problematic. Create a new variable, "negative", which indicates if a user's feedback is negative (Step 2: mutate). The following code will do these jobs for you. 

```{r}
ithelp<-ithelp%>%
  filter(Satisfaction!="0 - Unknown")%>%
  mutate(negative=as.factor(ifelse(Satisfaction =="1 - Unsatisfied","Yes","No")))

summary(ithelp)
```

# Set up for holdout validation
Let's select 20% of dataset. Using these indices, we will create a test and a training dataset. 
```{r}
set.seed(1)   # set a random seed 
index <- sample(nrow(ithelp), nrow(ithelp)*0.2) # random selection of indices. 
test <- ithelp[index,]       # save 20% as a test dataset
training <-ithelp[-index,]   # save the rest as a training set

```


# Tree model
```{r}
library(rpart)
library(rpart.plot)
```

Build the same model to predict "negative", with the following variables. 
* RequestorSeniority
* FiledAgainst
* TicketType
* Severity
* Priority
* daysOpen

But this time, we will make two changes. 
1. Instead of the entire dataset for training (ithelp), you will use the training dataset (training). 
2. Generate a bigger tree with cp=0. Set `control=rpart.control(cp=0)`. 

Save the model as `ct_model`. We will skip plotting the tree. It may crash.  
```{r}
ct_model<-rpart(negative~RequestorSeniority+FiledAgainst+TicketType+Severity+Priority+daysOpen,           # model formula
                data=training,                     # dataset
                method="class",                   # "class" indicates a classification tree model 
                control=rpart.control(cp=0))   # tree control parameters. 
```

Check the cross-validation result using `printcp()`. 
```{r}
printcp(ct_model)
```

Prune the tree using the cp value with the minimum xerror. Save the result as `min_xerror_tree`.  
```{r}

# prune tree with minimum cp value
min_xerror_tree <-
  prune(ct_model, cp = ct_model$cptable[which.min(ct_model$cptable[, "xerror"]), ][1])

```

Apply this model to the test dataset to get the predicted probabilities. 
```{r}
test$predicted_Prob <- predict(min_xerror_tree,test)[,2]
```

Using the 50% cut-off, generate class prediction.  
```{r}
test$predicted_Prob_YN <- ifelse(test$predicted_Prob>0.5,"Yes","No")
```

## Question 1. What is the error rate of this model when we use the 50% cut-off? 
```{r}
table(test$negative == test$predicted_Prob_YN)
nrow(test[test$negative != test$predicted_Prob_YN,]) / nrow(test)
```


## Question 2. Generate a confusion table of this model. What is the false positive rate of this model? 
```{r}
table(test$predicted_Prob_YN,
      test$negative,
      dnn = c("predicted", "actual"))
nrow(test %>% filter(test$predicted_Prob_YN == "Yes", test$negative == "No")) / nrow(test %>% filter(test$negative == "No"))
```

# Logit Regression Model
Using the training dataset, build a logit regression model to predict "negative", with the following variables. 
* RequestorSeniority
* FiledAgainst
* TicketType
* Severity
* Priority
* daysOpen

Again, be sure to use `training' dataset for model building. 

```{r}
logit_model <-
  glm(
    negative ~ RequestorSeniority + FiledAgainst + TicketType + Severity + Priority +
      daysOpen,
    # model formula
    data = training,
    family = "binomial"
  )
summary(logit_model)
```

Apply this model to the test dataset to get the predicted probabilities.  
```{r}
test$logit_pred_prob<-predict(logit_model,test,type="response")
test$logit_pred_class<-ifelse(test$logit_pred_prob>0.5,"Yes","No") 
```

# Performance Visualization with ROC

Plot ROC curves of the tree model and logit regression mode you developed. 
```{r}
library(pROC)
tree_roc <- roc(test$negative, test$predicted_Prob, auc=TRUE)
logit_roc<-roc(test$negative,test$logit_pred_prob,auc=TRUE)

plot(tree_roc, pront.auc = TRUE,col="blue")
plot(logit_roc,print.auc=TRUE,print.auc.y=.3,add=TRUE,col="red")
```

## Question 3. What are AUCs of the classification tree model?
```{r}
tree_roc$auc
```

## Question 4. What are AUCs of the logit regression model? 
```{r}
logit_roc$auc
```

## Question 5
The same as the previous assignments, your last task is creating a report. Change the author name on the top of this R markdown file to yours. Compile this R markdown file into a Word document and submit it through the course Blackboard. 




